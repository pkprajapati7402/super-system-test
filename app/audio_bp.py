import os
import numpy as np
import tensorflow as tf
from flask import Blueprint, request, jsonify, send_file
from typing import List, Dict
import tensorflow as tf
import tensorflow_hub as hub
import librosa
from app import client, model
from datetime import datetime
import json
from fpdf import FPDF
import cloudinary.uploader
from flask import make_response
from werkzeug.utils import secure_filename
from datetime import datetime
from app.report_generation import process_audio

# Configure upload settings
UPLOAD_FOLDER = 'uploads'
ALLOWED_EXTENSIONS = {'wav'}
MAX_CONTENT_LENGTH = 16 * 1024 * 1024  # 16MB max file size

# Create upload folder if it doesn't exist
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

CHATBOT_SYSTEM_PROMPT = {
    "role": "system",
    "content": (
        "You are AudiBuddy, an AI expert in voice and vocal health. You provide professional advice "
        "on vocal health, vocal exercises, speech disorders, and voice-related medical conditions. "
        "You do NOT respond to unrelated topics. If asked about anything outside your expertise, politely "
        "refuse to answer and redirect the user to vocal health topics. "
        "Always maintain context of the previous conversation to provide more relevant and personalized responses."
    )
}

label_mapping = {
    0: "Healthy",
    1: "Laryngitis",
    2: "Vocal Polyp"
}

vggish_model_url = "https://tfhub.dev/google/vggish/1"
vggish_model = hub.load(vggish_model_url)

audio_bp = Blueprint("audio", __name__)

conversation_history: List[Dict[str, str]] = [CHATBOT_SYSTEM_PROMPT]
MAX_HISTORY = 10

def trim_conversation_history():
    """Maintain conversation history within limits while preserving context."""
    global conversation_history
    if len(conversation_history) > (MAX_HISTORY * 2 + 1):  # +1 for system prompt
        conversation_history = [CHATBOT_SYSTEM_PROMPT, *conversation_history[-(MAX_HISTORY * 2):]]

def get_response(user_input: str) -> str:
    """Get AI response while maintaining conversation context."""
    global conversation_history
    conversation_history.append({"role": "user", "content": user_input})
    trim_conversation_history()

    completion = client.chat.completions.create(
        model="mixtral-8x7b-32768",
        messages=conversation_history,
        temperature=1,
        max_completion_tokens=1024,
        top_p=1,
        stream=False,
        stop=None,
    )

    response_text = completion.choices[0].message.content
    conversation_history.append({"role": "assistant", "content": response_text})
    return response_text

@audio_bp.route("/chat", methods=["POST"])
def chat():
    """Flask route to handle chatbot conversation."""
    data = request.json
    user_input = data.get("message", "").strip()

    if not user_input:
        return jsonify({"error": "Message cannot be empty"}), 400

    response_text = get_response(user_input)
    return jsonify({"response": response_text})

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

@audio_bp.route('/process_audio', methods=['POST'])
def process_audio_api():
    """API endpoint to process an audio file and return the analysis results."""
    try:
        # Check if the 'audio' key is in the request
        if 'audio' not in request.files:
            print("No audio file provided in the request.")
            return jsonify({'error': 'No audio file provided'}), 400

        file = request.files['audio']

        # Check if a file was selected
        if file.filename == '':
            print("No file selected.")
            return jsonify({'error': 'No selected file'}), 400

        # Validate the file type
        if not allowed_file(file.filename):
            print(f"Invalid file type: {file.filename}")
            return jsonify({'error': 'File type not allowed'}), 400

        # Secure the filename and save the file
        filename = secure_filename(file.filename)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        unique_filename = f"{timestamp}_{filename}"
        filepath = os.path.join(UPLOAD_FOLDER, unique_filename)
        file.save(filepath)

        print(f"File uploaded successfully: {filepath}")

        # Process the audio file using the process_audio function
        print(f"Processing audio file: {filepath}")
        json_report = process_audio(filepath)

        # Return the JSON report generated by process_audio
        return jsonify({'success': True, 'message': 'Audio processed successfully', 'report': json.loads(json_report)}), 200

    except Exception as e:
        print(f"Error in process_audio_api: {str(e)}")
        return jsonify({'error': f'Error processing audio: {str(e)}'}), 500

# âœ… Error handler for file too large
@audio_bp.errorhandler(413)
def too_large(e):
    return jsonify({'error': 'File is too large'}), 413